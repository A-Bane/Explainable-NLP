{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Responsible Approach.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPvJh+I5Ti35+Ecf1MMRmjJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/A-Bane/Explainable-NLP/blob/main/Responsible_Approach.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3VlUo-GLFK9"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvvXNYmEAr9U"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Flatten, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import re\n",
        "from sklearn.datasets import load_files\n",
        "from keras.layers import Dense,Conv1D,MaxPooling1D\n",
        "from keras import optimizers\n",
        "import random\n",
        "from keras import backend as K\n",
        "import cv2\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score,accuracy_score\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2RUWjG8AxYu",
        "outputId": "86943067-4c59-447c-b58b-afaac4a0862e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')\n",
        "dataset = load_files('/gdrive/My Drive/txt_sentoken')\n",
        "features, labels = dataset.data, dataset.target"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /gdrive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95jyYqaSLJUe"
      },
      "source": [
        "## Preprocessing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIlzkmm5IBIn"
      },
      "source": [
        "corpus = []\n",
        "corpus1 = []\n",
        "for i in range(len(features)):\n",
        "    review = re.sub(r'\\\\n', ' ', str(features[i]))\n",
        "    corpus1.append(review)\n",
        "\n",
        "for i in range(len(corpus1)):\n",
        "    # Removing all punctuation marks and non characters\n",
        "    review = re.sub(r'\\W', ' ', str(corpus1[i]))\n",
        "\n",
        "    # Converting into lowercase\n",
        "    review = review.lower()\n",
        "\n",
        "    # Removing b from starting of string\n",
        "    review = re.sub(r'^b\\s+', '', review)\n",
        "\n",
        "    # Removing all single characters\n",
        "    review = re.sub(r'\\s+[a-z]\\s+', ' ', review)\n",
        "\n",
        "    # Removing all words which is of length one\n",
        "    review = re.sub(r'[^a-z]\\s+', ' ', review)\n",
        "\n",
        "    # Removing all extra spaces\n",
        "    review = re.sub(r'\\s+', ' ', review)\n",
        "\n",
        "    # Adding cleaned reviews in corpus\n",
        "    corpus.append(review)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfsN3r0eIDPZ"
      },
      "source": [
        "import gensim\n",
        "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
        "from nltk.stem.porter import *\n",
        "import nltk"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6JUda_IFEh",
        "outputId": "b1cc2173-7309-427f-c2b4-46e8455d3952"
      },
      "source": [
        "nltk.download('wordnet')\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7q69C5aIGvq"
      },
      "source": [
        "def lemmatize_stemming(text):\n",
        "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
        "\n",
        "\n",
        "def preprocess(text):\n",
        "    result = []\n",
        "    for token in gensim.utils.simple_preprocess(text):\n",
        "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
        "            result.append(lemmatize_stemming(token))\n",
        "    return result\n",
        "\n",
        "\n",
        "processed_docs = []\n",
        "for i in corpus:\n",
        "    processed_docs.append(preprocess(i))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMTdRqryII9M"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=1500, split=' ')\n",
        "\n",
        "tokenizer.fit_on_texts(processed_docs)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(processed_docs)\n",
        "\n",
        "X = pad_sequences(X)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qnU4EsdOFJg",
        "outputId": "7f4529b7-860d-40e1-8e84-879b3496327a"
      },
      "source": [
        "labels = labels.reshape(-1, 1)\n",
        "Y = np.ravel(labels)\n",
        "# print(Y)\n",
        "# print(Y.shape)\n",
        "Y = pd.get_dummies(Y)\n",
        "Y = np.array(Y)\n",
        "print(Y)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " ...\n",
            " [0 1]\n",
            " [1 0]\n",
            " [1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKu0L6z2OHTm",
        "outputId": "5d742748-b565-4fac-964f-d03db3cb160f"
      },
      "source": [
        "X.shape\n",
        "#2000 samples are present"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2000, 751)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOhW0eKs7udX",
        "outputId": "9d610b79-e2ac-4bb5-aa99-8d31cbf35065"
      },
      "source": [
        "X[1].shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(751,)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5SiQ9qyLN6S"
      },
      "source": [
        "## Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89MtqwoMIoDj"
      },
      "source": [
        "def build_model(inp_length):\n",
        "  embedding_vector_length = 32\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(5000, embedding_vector_length, input_length=inp_length))\n",
        "  # model.add(Embedding(5000, embedding_vector_length, input_shape=inp_length))\n",
        "  model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(LSTM(100))\n",
        "  model.add(Dense(2, activation='sigmoid'))\n",
        "  #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  #print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEYfpCHoL6fD"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUrQwuH6fF78"
      },
      "source": [
        "def shuffle_in_unison(a, b, c, d):\n",
        "    rng_state = np.random.get_state()\n",
        "    np.random.shuffle(a)\n",
        "    np.random.set_state(rng_state)\n",
        "    np.random.shuffle(b)\n",
        "    np.random.set_state(rng_state)\n",
        "    np.random.shuffle(c)\n",
        "    np.random.set_state(rng_state)\n",
        "    np.random.shuffle(d)\n",
        "\n",
        "    return a, b, c, d"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mdi09jdKLB2d"
      },
      "source": [
        "def mini_batches(X, Y, mini_batch_size=64):\n",
        "    # Generate batches\n",
        "\n",
        "    m = X.shape[0]  # number of training examples=1700\n",
        "    mini_batches = []\n",
        "    \n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = int(np.floor(m / mini_batch_size))  # number of mini batches of size mini_batch_size in your partitionning=27\n",
        "    # print(num_complete_minibatches,\"-------------------\")\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = X[k * mini_batch_size: k * mini_batch_size + mini_batch_size, :]\n",
        "        # print(len(mini_batch_X))\n",
        "        mini_batch_Y = Y[k * mini_batch_size: k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "        \n",
        "\n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = X[num_complete_minibatches * mini_batch_size: m, :]\n",
        "        mini_batch_Y = Y[num_complete_minibatches * mini_batch_size: m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "\n",
        "    return mini_batches\n",
        "\n",
        "\n",
        "def lr_scheduler(epoch, maxepoch, max_lr=0.01, min_lr=0.005, cool_down_lr=0.0005):\n",
        "\n",
        "      learning_rate = max_lr + (epoch * (min_lr - max_lr) / maxepoch)\n",
        "\n",
        "      return learning_rate\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGT4akEmIupF"
      },
      "source": [
        "def train(args): \n",
        "\n",
        " \n",
        "  batch_size = args[\"batch_size\"]\n",
        "  maxepoch = args[\"maxepoches\"]\n",
        "  min_lr = args[\"min_lr\"]\n",
        "  max_lr = args[\"max_lr\"]\n",
        "  cool_down_lr = args[\"cool_down_lr\"]\n",
        "  lr = args[\"lr\"]\n",
        "  optimizer = args[\"optimizer\"]\n",
        "  \n",
        "  num_classes = args[\"num_classes\"]\n",
        "\n",
        "  x_train = args[\"x_train\"] \n",
        "  y_train = args[\"y_train\"] \n",
        "  x_test = args[\"x_test\"] \n",
        "  y_test = args[\"y_test\"] \n",
        "\n",
        "  num_samples = (x_train.shape)[0]\n",
        "  num_minibatches = int(np.ceil(num_samples / batch_size))\n",
        "\n",
        "  total_delta_weights_dense2 = [0] * num_samples\n",
        "  print(\"Number of MiniBatches:\", num_minibatches)\n",
        "\n",
        "  # model = build_model2(X.shape[0])\n",
        "  model = build_model(751)\n",
        "  if optimizer == \"sgd\":\n",
        "    opt = optimizers.SGD(lr=lr, momentum=0.9, nesterov=True)\n",
        "  elif optimizer == \"adam\":\n",
        "    opt = Adam(learning_rate=min_lr)\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  \n",
        "  for epoch in range(maxepoch):\n",
        "    num_minibatches = int(num_samples / batch_size)\n",
        "    minibatches = mini_batches(x_train, y_train, batch_size)\n",
        "\n",
        " \n",
        "    learning_rate = lr_scheduler(epoch=epoch, maxepoch=maxepoch, max_lr=max_lr, min_lr=min_lr, cool_down_lr=cool_down_lr)\n",
        "    \n",
        "    if optimizer == \"sgd\":\n",
        "      opt = optimizers.SGD(learning_rate=learning_rate, momentum=0.9, nesterov=True)\n",
        "    elif optimizer == \"adam\":\n",
        "      opt = Adam(learning_rate=learning_rate)\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    print(\"---------------------------------------------------\", \"Epoch:\", epoch+1, \"Learning Rate:\", learning_rate, \"-----------------------------------------------------------------------\")\n",
        "  \n",
        "    counter = 0\n",
        "    count = 0\n",
        "\n",
        "    for minibatch in minibatches:\n",
        "        \n",
        "        (train_sample_x, train_sample_y) = minibatch\n",
        "        # print(len(train_sample_x)) Each minibatch has 64 elements\n",
        "\n",
        "        # print(\"SHAPE\",len(model.layers[-1].get_weights())) SHAPE: 2\n",
        "        \n",
        "        \n",
        "\n",
        "        pre_weights_dense2 = np.array(model.layers[-1].get_weights()[0]) # before training 64 samples (100 weights)\n",
        "        \n",
        "\n",
        "        counter += 1\n",
        "        \n",
        "\n",
        "        model.fit(train_sample_x, train_sample_y,\n",
        "                  batch_size=batch_size,\n",
        "                  shuffle=False, \n",
        "                  epochs=1,\n",
        "                  verbose=0)\n",
        "\n",
        "      \n",
        "        post_weights_dense2 = np.array(model.layers[-1].get_weights()[0])# after training 64 samples (100 weights)\n",
        "        \n",
        "        \n",
        "        delta_weights_dense2 = np.subtract(post_weights_dense2, pre_weights_dense2) # len=100 \n",
        "        #print(len(delta_weights_dense2),\"OVER\")\n",
        "\n",
        "        for i in range(len(train_sample_x)): # for each of 64 training samples\n",
        "          total_delta_weights_dense2[i + count] = np.add(total_delta_weights_dense2[i + count], delta_weights_dense2)\n",
        "          # delta_weights_dense2 is repeated for each sample. \n",
        "\n",
        "        count += len(train_sample_x)\n",
        "    \n",
        "    print(\"Train Scores:\")\n",
        "    tr_loss, tr_acc = model.evaluate(x=x_train, y=y_train, verbose=1)\n",
        "    print(\"Test Scores:\")\n",
        "    val_loss, val_acc = model.evaluate(x=x_test, y=y_test, verbose=1) \n",
        "    \n",
        "    \n",
        "  return model, total_delta_weights_dense2"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgnjLJFLL_eq"
      },
      "source": [
        "## Train Test Split of the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WE2vZ1J8OsOH"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.15, random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc14PRECarhh"
      },
      "source": [
        "x_val, x_unseen, y_val, y_unseen = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXQOjndvMGIS"
      },
      "source": [
        "## Training of the actor model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krocVc2IOmIs",
        "outputId": "533babcf-0f81-4435-d9f5-638713ec00d8"
      },
      "source": [
        "my_args = {\"batch_size\": 1,\n",
        "\"maxepoches\": 8,\n",
        "\"min_lr\": 0.0001,\n",
        "\"max_lr\": 0.001,\n",
        "\"cool_down_lr\": 0.0005,\n",
        "\"lr\": 0.001,\n",
        "\n",
        "\"optimizer\": \"adam\", # different optimizers: adam, sgd\n",
        "\"num_classes\": 2,\n",
        "\"x_train\": X_train, \n",
        "\"y_train\": y_train,\n",
        "\"x_test\": X_test,\n",
        "\"y_test\": y_test\n",
        "}\n",
        "\n",
        "#  random.seed(73)\n",
        "model, total_delta_weights_dense2 = train(my_args)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of MiniBatches: 1700\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 751, 32)           160000    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, 751, 32)           3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 375, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 216,506\n",
            "Trainable params: 216,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "--------------------------------------------------- Epoch: 1 Learning Rate: 0.001 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.4937 - accuracy: 0.7606\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.6807 - accuracy: 0.6400\n",
            "--------------------------------------------------- Epoch: 2 Learning Rate: 0.0008875 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.2345 - accuracy: 0.9247\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.5513 - accuracy: 0.7000\n",
            "--------------------------------------------------- Epoch: 3 Learning Rate: 0.0007750000000000001 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.1201 - accuracy: 0.9588\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.6000 - accuracy: 0.7567\n",
            "--------------------------------------------------- Epoch: 4 Learning Rate: 0.0006625 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.0569 - accuracy: 0.9806\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 27ms/step - loss: 0.7728 - accuracy: 0.7733\n",
            "--------------------------------------------------- Epoch: 5 Learning Rate: 0.00055 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.0500 - accuracy: 0.9865\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.7471 - accuracy: 0.7467\n",
            "--------------------------------------------------- Epoch: 6 Learning Rate: 0.00043750000000000006 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.0230 - accuracy: 0.9947\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 29ms/step - loss: 0.8692 - accuracy: 0.7633\n",
            "--------------------------------------------------- Epoch: 7 Learning Rate: 0.000325 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 29ms/step - loss: 0.0188 - accuracy: 0.9941\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 28ms/step - loss: 0.9116 - accuracy: 0.7800\n",
            "--------------------------------------------------- Epoch: 8 Learning Rate: 0.00021250000000000002 -----------------------------------------------------------------------\n",
            "Train Scores:\n",
            "54/54 [==============================] - 2s 28ms/step - loss: 0.0091 - accuracy: 0.9988\n",
            "Test Scores:\n",
            "10/10 [==============================] - 0s 30ms/step - loss: 0.9772 - accuracy: 0.7900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xy0i-37NK3o"
      },
      "source": [
        "## Responsibility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAjLmtnycpEV"
      },
      "source": [
        "def responsibility(total_delta_weights):\n",
        "  arr = np.array(total_delta_weights, dtype=np.float16)\n",
        "  print(\"Layer delta weights:\", arr.shape) #1700 samples and each sample has 100 channels\n",
        "  print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "  argmax_array = np.argmax(arr, axis=0)\n",
        "  print(\"Most Responsible Positive Array ---- Shape:\", argmax_array.shape)\n",
        "  # counts_max = np.bincount(argmax_array.flatten())\n",
        "  # print(\"Most Frequent Index:\", counts_max.argsort()[-10:][::-1])\n",
        "  # print(\"----------------------------------------------------------------------\")\n",
        "\n",
        "  return argmax_array"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4TIaQzfc8wO",
        "outputId": "aa78e25e-d98f-48c0-e603-8b00d9cd51d2"
      },
      "source": [
        "array_of_IDs_of_positive_most_responsible_samples = responsibility(total_delta_weights_dense2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer delta weights: (1700, 100, 2)\n",
            "----------------------------------------------------------------------\n",
            "Most Responsible Positive Array ---- Shape: (100, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQY3BuH6Qu2z"
      },
      "source": [
        "model.save_weights('/gdrive/MyDrive/Model_Weights.h5')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vgi8R82dPDCG",
        "outputId": "bcae43cd-19ed-42a5-98f1-bfbe4b15eb4b"
      },
      "source": [
        "print(len(total_delta_weights_dense2))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qh3-dGtgn4e7",
        "outputId": "b7d0e5c3-877a-47e4-c026-1840c01e4bb5"
      },
      "source": [
        "predicted_y = model.predict(x_val)\n",
        "# predicted_y=predicted_y.reshape(y_test.shape[0],)\n",
        "# predicted_y = pd.get_dummies(predicted_y)\n",
        "predicted_y = np.array(predicted_y)\n",
        "residuals = np.argmax(predicted_y,1)!=np.argmax(y_val,1) \n",
        "print(residuals)\n",
        "\n",
        "loss = sum(residuals)/len(residuals)\n",
        "print(\"The Test 0/1 loss is: \", loss)\n",
        "\n",
        "print(\"Number of Incorrect samples:\", sum(residuals))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False  True  True False False False False False False\n",
            "  True False False  True False False False False False False False False\n",
            " False False False False  True  True False False  True False False False\n",
            " False False False False False False False False False  True False False\n",
            " False False False False  True False False  True False False False False\n",
            " False False False  True False False  True False False False False False\n",
            " False  True False False False  True False False False False False False\n",
            " False False False False False False False  True False False False False\n",
            " False False  True False  True False False False  True False  True  True\n",
            "  True False False False  True False False False  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False False False False  True False False False  True False  True False\n",
            " False False False False False  True]\n",
            "The Test 0/1 loss is:  0.18\n",
            "Number of Incorrect samples: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-N79MsioEVm",
        "outputId": "e64c2afd-d6c6-4314-91ae-7a702b4565de"
      },
      "source": [
        "predicted_y_tr = model.predict(X_train, batch_size=1)\n",
        "# predicted_y_tr = pd.get_dummies(predicted_y_tr)\n",
        "predicted_y_tr = np.array(predicted_y_tr)\n",
        "residuals_tr = np.argmax(predicted_y_tr,1)!=np.argmax(y_train,1) \n",
        "print(residuals_tr)\n",
        "\n",
        "loss_tr = sum(residuals_tr)/len(residuals_tr)\n",
        "print(\"The Train 0/1 loss is: \", loss_tr)\n",
        "\n",
        "print(\"Number of Incorrect samples:\", sum(residuals_tr))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False ... False False False]\n",
            "The Train 0/1 loss is:  0.001176470588235294\n",
            "Number of Incorrect samples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL7yDTydoejD",
        "outputId": "641cbd51-445b-4113-9a31-2fa513d7071f"
      },
      "source": [
        "# Final Data for the Second Model \n",
        "\n",
        "incorrect_indecies = list([i for i, x in enumerate(residuals) if x])\n",
        "correct_indecies = [a for a in range(x_val.shape[0]) if a not in incorrect_indecies]\n",
        "\n",
        "print(len(incorrect_indecies), \"+\", len(correct_indecies), \"=\", len(x_val))\n",
        "\n",
        "\n",
        "incorrect_samples = []\n",
        "incorrect_x = []\n",
        "incorrect_y = []\n",
        "incorrect_y_true = []\n",
        "incorrect_y_pred = []\n",
        "# All (X_train+x_val) values which were wrongly predicted.\n",
        "\n",
        "for ind in incorrect_indecies:\n",
        "  incorrect_x.append(x_val[ind])\n",
        "  incorrect_y.append(0.0)\n",
        "  incorrect_y_true.append(y_val[ind])\n",
        "  incorrect_y_pred.append(predicted_y[ind])\n",
        "len_incorrect_x=len(incorrect_x)\n",
        "print(\"Only incorrectly predicts of x test: \",len(incorrect_x))\n",
        "\n",
        "\n",
        "incorrect_indecies_tr = list([i for i, x in enumerate(residuals_tr) if x]) # incorrect X_train \n",
        "\n",
        "for ind_tr in incorrect_indecies_tr:\n",
        "  incorrect_x.append(X_train[ind_tr])\n",
        "  incorrect_y.append(0.0)\n",
        "  incorrect_y_true.append(y_train[ind_tr])\n",
        "  incorrect_y_pred.append(predicted_y_tr[ind_tr])\n",
        "\n",
        "print(\"Incorrects Done! \\nLength =\", len(incorrect_x))\n",
        "print(\"Length of Wrong x train predicts = \",len(incorrect_x)-len_incorrect_x )\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "27 + 123 = 150\n",
            "Only incorrectly predicts of x test:  27\n",
            "Incorrects Done! \n",
            "Length = 29\n",
            "Length of Wrong x train predicts =  2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H-lmj656ua1"
      },
      "source": [
        "*Wrongly predicts are << Correctly predicted* \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONVlj2jO5MWR",
        "outputId": "a76b32a8-4035-40c6-8fa5-6c9636ae3139"
      },
      "source": [
        "correct_indecies = random.sample(correct_indecies, len(incorrect_x)) # sampled only from correctly predicts X_test\n",
        "\n",
        "correct_samples = []\n",
        "correct_x = []\n",
        "correct_y = []\n",
        "correct_y_true = []\n",
        "correct_y_pred = []\n",
        "for ind in correct_indecies:\n",
        "  correct_x.append(x_val[ind]) # prev comment makes sense\n",
        "  correct_y.append(1.0) # 1 means correctly predicted\n",
        "  correct_y_true.append(y_val[ind])\n",
        "  correct_y_pred.append(predicted_y[ind])\n",
        "\n",
        "print(\"Corrects Done! \\nLength =\", len(correct_x))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corrects Done! \n",
            "Length = 29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3nFZmjwdgYlO",
        "outputId": "5136cd88-3ebf-4da8-ecf3-0a6c37511c93"
      },
      "source": [
        "x_train_list = correct_x + incorrect_x\n",
        "y_train_list = correct_y + incorrect_y\n",
        "y_true_list = correct_y_true + incorrect_y_true\n",
        "y_pred_list = correct_y_pred + incorrect_y_pred\n",
        "\n",
        "final_x_train = np.array(x_train_list)\n",
        "final_y_train = np.array(y_train_list)\n",
        "final_y_true = np.array(y_true_list)\n",
        "final_y_pred = np.array(y_pred_list)\n",
        "\n",
        "final_x_train, final_y_train, final_y_true, final_y_pred = shuffle_in_unison(final_x_train, final_y_train, final_y_true, final_y_pred)\n",
        "\n",
        "print(\"Final X and Y Shape:\", final_x_train.shape, final_y_train.shape, final_y_true.shape, final_y_pred.shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final X and Y Shape: (58, 751) (58,) (58, 2) (58, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZjCCI3CLp4w",
        "outputId": "c63f2053-a9b0-4580-8bc4-be45f9d7c04d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1700, 751)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLc6tOUoPbxC"
      },
      "source": [
        "model = build_model(751)\n",
        "model.load_weights('/gdrive/MyDrive/Model_Weights.h5')"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YSvfw249lMc"
      },
      "source": [
        "def finding_resp_samples_wx_method(sample, model, ind_array_fc_pos, training_samples):\n",
        "  inp = model.input  # input placeholder\n",
        "  \n",
        "  outputs = [layer.output for layer in model.layers]  # all layer outputs\n",
        "  # print(outputs)\n",
        "  functor = K.function([inp], outputs)  # evaluation function\n",
        "  sample = np.reshape(sample, (1,751))\n",
        "  layer_outs = functor([sample])\n",
        "  \n",
        "  # print(\"-----\",layer_outs[-1])\n",
        "  # print(\"-----\",layer_outs[-2].shape)\n",
        "  \n",
        "  dense_out = layer_outs[-1]\n",
        "  dense_in = layer_outs[-2]\n",
        "\n",
        "\n",
        "  max_ind_fc = np.argmax(dense_out) # 0 or 1\n",
        "  \n",
        "\n",
        "  fc_layer_weights = np.array(model.layers[-1].get_weights()[0]) # 2 dense nodes, so 2 weights column, In each coln, 100 weights are there for 1 sample\n",
        "  # print(len(fc_layer_weights))\n",
        "\n",
        "  # print(\"-------------------------\")\n",
        "\n",
        "  max_weights = fc_layer_weights[:, max_ind_fc] # which ever nodes' output is max, loading the ACTUAL weights for the sample\n",
        "  # print(len(max_weights))\n",
        "  dense_in=dense_in.reshape(100,)\n",
        "  \n",
        "\n",
        "  w = []\n",
        "  x = []\n",
        "  wx = []\n",
        "  for i in range(len(max_weights)):\n",
        "    w.append(max_weights[i])\n",
        "    x.append(dense_in[i])\n",
        "    wx.append(max_weights[i] * dense_in[i])\n",
        "\n",
        "\n",
        "  pos_most_resp_1 = training_samples[ind_array_fc_pos[np.argmax(wx), max_ind_fc]]\n",
        "\n",
        "  return pos_most_resp_1, wx\n",
        "  "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpxVyBmK9sFs"
      },
      "source": [
        "XY_tuples = []\n",
        "for i in range(len(final_x_train)):\n",
        "    sample = final_x_train[i]\n",
        "    # print(sample.reshape(751,))\n",
        "    \n",
        "    prediction = final_y_train[i]\n",
        "    y_truee = final_y_true[i]\n",
        "    y_pred = final_y_pred[i]\n",
        "\n",
        "    # print(\"y true:\", y_truee)\n",
        "    # print(\"ypred:\", y_pred)\n",
        "    # print(\"prediction:\", prediction)\n",
        "\n",
        "    pos_most_resp_1, wx = finding_resp_samples_wx_method(\n",
        "          sample, model,\n",
        "          array_of_IDs_of_positive_most_responsible_samples,\n",
        "          X_train)\n",
        "    # print(pos_most_resp_1)\n",
        "    XY_tuples.append((sample, pos_most_resp_1, prediction, y_truee, y_pred, wx))\n",
        "\n",
        "# print(XY_tuples[1])"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1aix7mOydS42"
      },
      "source": [
        "### Unseen Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7vXtjN9dhYM"
      },
      "source": [
        "# x_val, x_unseen, y_val, y_unseen = train_test_split(X_test, y_test, test_size=0.5, random_state=42, stratify=y_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Zs5A3GzhRX4",
        "outputId": "83354e61-eb4f-4ea7-cacc-ebd33b7a5949"
      },
      "source": [
        "# Generating Data for Model 2\n",
        "\n",
        "predicted_y_un = model.predict(x_unseen, batch_size=1)\n",
        "# print(predicted_y_un)\n",
        "# predicted_y_un = pd.get_dummies(predicted_y_un)\n",
        "# predicted_y_un = np.array(predicted_y_un)\n",
        "\n",
        "residuals_un = np.argmax(predicted_y_un,1)!=np.argmax(y_unseen,1)\n",
        "print(residuals_un)\n",
        "loss_un = sum(residuals_un)/len(residuals_un)\n",
        "print(\"The Test 0/1 loss is: \", loss_un)\n",
        "\n",
        "print(\"Number of Incorrect samples:\", sum(residuals_un))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[False False False False False False  True  True  True False False False\n",
            " False False False False False False False False False False False False\n",
            " False  True False False False False False  True False False  True False\n",
            " False False False False False False False  True False  True False False\n",
            " False  True False False False  True False False  True False False False\n",
            " False  True  True False  True False  True False False False False False\n",
            " False False False False  True  True  True  True False False False False\n",
            " False  True False False False False False False False  True False False\n",
            " False False False False  True False  True False False False  True False\n",
            " False  True  True False False  True False False False False False  True\n",
            "  True  True  True  True False False False False False False False False\n",
            "  True  True False False False False False False False False False  True\n",
            " False False False False False  True]\n",
            "The Test 0/1 loss is:  0.24\n",
            "Number of Incorrect samples: 36\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEV3mpbThT7B",
        "outputId": "cc05d708-13e4-4ea3-d412-c8d76cd0c448"
      },
      "source": [
        "# Generating Data for Model 2\n",
        "\n",
        "incorrect_indecies = list([i for i, x in enumerate(residuals_un) if x])\n",
        "correct_indecies = [a for a in range(x_unseen.shape[0]) if a not in incorrect_indecies]\n",
        "\n",
        "print(len(incorrect_indecies), \"+\", len(correct_indecies), \"=\", len(x_unseen))\n",
        "\n",
        "\n",
        "# correct_indecies = random.sample(correct_indecies, len(incorrect_indecies))\n",
        "\n",
        "incorrect_samples = []\n",
        "incorrect_x = []\n",
        "incorrect_y = []\n",
        "incorrect_y_true = []\n",
        "incorrect_y_pred = []\n",
        "for ind in incorrect_indecies:\n",
        "  incorrect_x.append(x_unseen[ind])\n",
        "  incorrect_y.append(0.0)\n",
        "  incorrect_y_true.append(y_unseen[ind])\n",
        "  incorrect_y_pred.append(predicted_y_un[ind])\n",
        "\n",
        "\n",
        "\n",
        "correct_samples = []\n",
        "correct_x = []\n",
        "correct_y = []\n",
        "correct_y_true = []\n",
        "correct_y_pred = []\n",
        "for ind in correct_indecies:\n",
        "  correct_x.append(x_unseen[ind])\n",
        "  correct_y.append(1.0)\n",
        "  correct_y_true.append(y_unseen[ind])\n",
        "  correct_y_pred.append(predicted_y_un[ind])\n",
        "\n",
        "x_train_list = correct_x + incorrect_x\n",
        "y_train_list = correct_y + incorrect_y\n",
        "y_true_list = correct_y_true + incorrect_y_true\n",
        "y_pred_list = correct_y_pred + incorrect_y_pred\n",
        "\n",
        "final_x_train = np.array(x_train_list)\n",
        "final_y_train = np.array(y_train_list)\n",
        "final_y_true = np.array(y_true_list)\n",
        "final_y_pred = np.array(y_pred_list)\n",
        "\n",
        "final_x_train, final_y_train, final_y_true, final_y_pred = shuffle_in_unison(final_x_train, final_y_train, final_y_true, final_y_pred)\n",
        "\n",
        "print(\"Final X and Y Shape:\", final_x_train.shape, final_y_train.shape, final_y_true.shape, final_y_pred.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "36 + 114 = 150\n",
            "Final X and Y Shape: (150, 751) (150,) (150, 2) (150, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTd1ob2sfC5_"
      },
      "source": [
        "XY_tuples_unseen = []\n",
        "for i in range(len(final_x_train)):\n",
        "  sample = final_x_train[i]\n",
        "  prediction = final_y_train[i]\n",
        "  y_truee = final_y_true[i]\n",
        "  y_pred = final_y_pred[i]\n",
        "\n",
        "  # print(\"y true:\", y_truee)\n",
        "  # print(\"ypred:\", y_pred)\n",
        "  # print(\"prediction:\", prediction)\n",
        "\n",
        "  pos_most_resp_1, wx = finding_resp_samples_wx_method(\n",
        "          sample, model,\n",
        "          array_of_IDs_of_positive_most_responsible_samples,\n",
        "          X_train)\n",
        "    # print(responsible_IDs)\n",
        "  XY_tuples_unseen.append((sample, pos_most_resp_1, prediction, y_truee, y_pred, wx))\n",
        "\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p307mD3_fiu4",
        "outputId": "5f74dca1-057e-411d-da86-171fc28a7944"
      },
      "source": [
        "str(len(XY_tuples_unseen)) +\" <--Unseen   Train--> \"+ str(len(XY_tuples))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'150 <--Unseen   Train--> 58'"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdsTSYREfnch"
      },
      "source": [
        "## Loading data for critic Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kpd-rqRfvzm"
      },
      "source": [
        "def load_data(train_tuples, unseen_tuples):\n",
        "  \n",
        "  samples = []\n",
        "  resp_samples = []\n",
        "  y = []\n",
        "  y_trues = []\n",
        "  y_preds = []\n",
        "  for tpl in train_tuples:\n",
        "    samples.append(tpl[0])\n",
        "    resp_samples.append(tpl[1])\n",
        "    y_trues.append(tpl[3])\n",
        "    y_preds.append(tpl[4])\n",
        "\n",
        "    if tpl[2] == 0:\n",
        "      y.append([1.0,0.0])\n",
        "    elif tpl[2] == 1:\n",
        "      y.append([0.0,1.0])\n",
        "\n",
        "  unseen_samples = []\n",
        "  unseen_resp_samples = []\n",
        "  unseen_y = []\n",
        "  unseen_y_trues = []\n",
        "  unseen_y_preds = []\n",
        "  for unseen_tpl in unseen_tuples:\n",
        "    unseen_samples.append(unseen_tpl[0])\n",
        "    unseen_resp_samples.append(unseen_tpl[1])\n",
        "    unseen_y_trues.append(unseen_tpl[3])\n",
        "    unseen_y_preds.append(unseen_tpl[4])\n",
        "\n",
        "    if unseen_tpl[2] == 0:\n",
        "      unseen_y.append([1.0,0.0])\n",
        "    elif unseen_tpl[2] == 1:\n",
        "      unseen_y.append([0.0,1.0])\n",
        "\n",
        "  samples, unseen_samples = np.array(samples), np.array(unseen_samples)\n",
        "  resp_samples, unseen_resp_samples = np.array(resp_samples), np.array(unseen_resp_samples)\n",
        "\n",
        "\n",
        "  y = np.array(y)\n",
        "  unseen_y = np.array(unseen_y)\n",
        "\n",
        "  print('Training Data:')\n",
        "  print(\"Input Image Shapes:\", samples.shape, resp_samples.shape)\n",
        "  print(\"Output shape:\", y.shape)\n",
        "\n",
        "  print('Unseen Data:')\n",
        "  print(\"Input Image Shapes:\", unseen_samples.shape, unseen_resp_samples.shape)\n",
        "  print(\"Output shape:\", unseen_y.shape)\n",
        "  return samples, resp_samples, y, y_trues, y_preds, unseen_samples, unseen_resp_samples, unseen_y, unseen_y_trues, unseen_y_preds"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7ZaPQaze2_Q",
        "outputId": "9de207cb-d291-4c30-8763-b1f802b01252"
      },
      "source": [
        "samples, resp_samples, y, y_trues, y_preds, samples_unseen, resp_samples_unseen, y_unseen, y_trues_unseen, y_preds_unseen = load_data(XY_tuples, XY_tuples_unseen)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data:\n",
            "Input Image Shapes: (58, 751) (58, 751)\n",
            "Output shape: (58, 2)\n",
            "Unseen Data:\n",
            "Input Image Shapes: (150, 751) (150, 751)\n",
            "Output shape: (150, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZmcKFyDihvr",
        "outputId": "d769421c-cbe1-4800-9161-5709a174768e"
      },
      "source": [
        "train_index=range(len(samples))\n",
        "y_train=y\n",
        "\n",
        "train_samples = []\n",
        "train_resps = []\n",
        "train_trues = []\n",
        "train_preds = []\n",
        "\n",
        "# y_train = []\n",
        "for ind in train_index:\n",
        "  train_samples.append(samples[ind])\n",
        "  train_resps.append(resp_samples[ind])\n",
        "  train_trues.append(y_trues[ind])\n",
        "  train_preds.append(y_preds[ind])\n",
        "  # y_train.append(y[ind])\n",
        "\n",
        "train_samples = np.array(train_samples)\n",
        "train_resps = np.array(train_resps)\n",
        "train_trues = np.array(train_trues)\n",
        "train_preds = np.array(train_preds)\n",
        "# y_train = np.array(y_train)\n",
        "\n",
        "\n",
        "\n",
        "print(\"Training set:\", train_resps.shape, train_samples.shape, y_train.shape, train_preds.shape, train_trues.shape)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set: (58, 751) (58, 751) (58, 2) (58, 2) (58, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfdBzIcHfuxU"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Htel7n7HfGkL"
      },
      "source": [
        "def train2(args): \n",
        "  batch_size = args[\"batch_size\"]\n",
        "  maxepoch = args[\"maxepoches\"]\n",
        "  min_lr = args[\"min_lr\"]\n",
        "  max_lr = args[\"max_lr\"]\n",
        "  cool_down_lr = args[\"cool_down_lr\"]\n",
        "  lr = args[\"lr\"]\n",
        "    \n",
        "  optimizer = args[\"optimizer\"]\n",
        "  train_samples = args[\"train_samples\"]\n",
        "\n",
        "  train_resps = args[\"train_resps\"]\n",
        "\n",
        "  y_train = args[\"y_train\"]\n",
        "\n",
        "  model = None\n",
        "\n",
        "  def lr_scheduler(epoch):\n",
        "      if epoch <= 0.6 * maxepoch:\n",
        "        learning_rate = max_lr\n",
        "      else:\n",
        "        learning_rate = max_lr + ((epoch + 1 - (0.6 * maxepoch)) * (min_lr - max_lr) / (0.4 * maxepoch) )\n",
        "      print(\"Epoch:\", epoch, \"Learning Rate:\", learning_rate)\n",
        "      return learning_rate\n",
        "\n",
        "  model = build_model(751*2)\n",
        "  reduce_lr = keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
        "  if optimizer == \"sgd\":\n",
        "    opt = optimizers.SGD(learning_rate=min_lr, momentum=0.9, nesterov=True)\n",
        "  elif optimizer == \"adam\":\n",
        "    opt = Adam(learning_rate=min_lr)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "\n",
        "  x_train = np.concatenate((train_samples, train_resps), axis=1)\n",
        "  print(x_train.shape)\n",
        "  history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True, \n",
        "                    epochs=maxepoch,\n",
        "                    validation_split=0.2,\n",
        "                    callbacks=[reduce_lr],\n",
        "                    verbose=1)\n",
        "  \n",
        "  return model, history"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Fhxtoq_hrxO",
        "outputId": "2e845016-d619-4481-8978-e8c0fedb734a"
      },
      "source": [
        "train_resps.shape"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(58, 751)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-8xFdUAlpu-",
        "outputId": "a840b341-e2c9-45ea-bf65-2133bbf4e8d6"
      },
      "source": [
        "my_args = {\"batch_size\": 15,\n",
        "\"maxepoches\": 50,\n",
        "\"min_lr\": 0.001,\n",
        "\"max_lr\": 0.01,\n",
        "\"cool_down_lr\": 0.00001,\n",
        "\"lr\": 0.001,\n",
        "\n",
        "\"optimizer\": \"adam\", # different optimizers: adam, sgd\n",
        "\"train_samples\": train_samples, \n",
        "\n",
        "\"train_resps\": train_resps,\n",
        "\n",
        "\"y_train\": y_train,\n",
        "}\n",
        "\n",
        "model, hist = train2(my_args)\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 1502, 32)          160000    \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 1502, 32)          3104      \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 751, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 202       \n",
            "=================================================================\n",
            "Total params: 216,506\n",
            "Trainable params: 216,506\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "(58, 1502)\n",
            "Epoch 1/50\n",
            "Epoch: 0 Learning Rate: 0.01\n",
            "4/4 [==============================] - 3s 340ms/step - loss: 0.7058 - accuracy: 0.3478 - val_loss: 0.6952 - val_accuracy: 0.5833\n",
            "Epoch 2/50\n",
            "Epoch: 1 Learning Rate: 0.01\n",
            "4/4 [==============================] - 1s 134ms/step - loss: 0.6926 - accuracy: 0.4783 - val_loss: 0.6990 - val_accuracy: 0.5833\n",
            "Epoch 3/50\n",
            "Epoch: 2 Learning Rate: 0.01\n",
            "4/4 [==============================] - 1s 129ms/step - loss: 0.6970 - accuracy: 0.4783 - val_loss: 0.7092 - val_accuracy: 0.5833\n",
            "Epoch 4/50\n",
            "Epoch: 3 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 124ms/step - loss: 0.6892 - accuracy: 0.4783 - val_loss: 0.7194 - val_accuracy: 0.5833\n",
            "Epoch 5/50\n",
            "Epoch: 4 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 126ms/step - loss: 0.6880 - accuracy: 0.4783 - val_loss: 0.7477 - val_accuracy: 0.2500\n",
            "Epoch 6/50\n",
            "Epoch: 5 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.6818 - accuracy: 0.6087 - val_loss: 0.7742 - val_accuracy: 0.2500\n",
            "Epoch 7/50\n",
            "Epoch: 6 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 127ms/step - loss: 0.6782 - accuracy: 0.5870 - val_loss: 0.8094 - val_accuracy: 0.3333\n",
            "Epoch 8/50\n",
            "Epoch: 7 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 125ms/step - loss: 0.6727 - accuracy: 0.6087 - val_loss: 0.8638 - val_accuracy: 0.3333\n",
            "Epoch 9/50\n",
            "Epoch: 8 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 122ms/step - loss: 0.6714 - accuracy: 0.6087 - val_loss: 1.1053 - val_accuracy: 0.2500\n",
            "Epoch 10/50\n",
            "Epoch: 9 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 120ms/step - loss: 0.6913 - accuracy: 0.5870 - val_loss: 1.2296 - val_accuracy: 0.2500\n",
            "Epoch 11/50\n",
            "Epoch: 10 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 117ms/step - loss: 0.6919 - accuracy: 0.6087 - val_loss: 1.1788 - val_accuracy: 0.2500\n",
            "Epoch 12/50\n",
            "Epoch: 11 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6863 - accuracy: 0.5870 - val_loss: 1.0200 - val_accuracy: 0.2500\n",
            "Epoch 13/50\n",
            "Epoch: 12 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.6582 - accuracy: 0.6087 - val_loss: 0.8866 - val_accuracy: 0.2500\n",
            "Epoch 14/50\n",
            "Epoch: 13 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.6511 - accuracy: 0.6087 - val_loss: 0.8164 - val_accuracy: 0.2500\n",
            "Epoch 15/50\n",
            "Epoch: 14 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6448 - accuracy: 0.6087 - val_loss: 0.7921 - val_accuracy: 0.2500\n",
            "Epoch 16/50\n",
            "Epoch: 15 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6406 - accuracy: 0.6087 - val_loss: 0.7881 - val_accuracy: 0.2500\n",
            "Epoch 17/50\n",
            "Epoch: 16 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6386 - accuracy: 0.6087 - val_loss: 0.8012 - val_accuracy: 0.2500\n",
            "Epoch 18/50\n",
            "Epoch: 17 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.6350 - accuracy: 0.6087 - val_loss: 0.8284 - val_accuracy: 0.2500\n",
            "Epoch 19/50\n",
            "Epoch: 18 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6347 - accuracy: 0.6087 - val_loss: 0.8382 - val_accuracy: 0.2500\n",
            "Epoch 20/50\n",
            "Epoch: 19 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.6349 - accuracy: 0.5870 - val_loss: 0.8661 - val_accuracy: 0.2500\n",
            "Epoch 21/50\n",
            "Epoch: 20 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6349 - accuracy: 0.5870 - val_loss: 0.8578 - val_accuracy: 0.2500\n",
            "Epoch 22/50\n",
            "Epoch: 21 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 113ms/step - loss: 0.6328 - accuracy: 0.6739 - val_loss: 0.8095 - val_accuracy: 0.5000\n",
            "Epoch 23/50\n",
            "Epoch: 22 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6521 - accuracy: 0.5217 - val_loss: 0.8123 - val_accuracy: 0.2500\n",
            "Epoch 24/50\n",
            "Epoch: 23 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6295 - accuracy: 0.6087 - val_loss: 0.8589 - val_accuracy: 0.2500\n",
            "Epoch 25/50\n",
            "Epoch: 24 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6354 - accuracy: 0.6087 - val_loss: 0.8878 - val_accuracy: 0.2500\n",
            "Epoch 26/50\n",
            "Epoch: 25 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.6471 - accuracy: 0.5217 - val_loss: 0.8584 - val_accuracy: 0.5833\n",
            "Epoch 27/50\n",
            "Epoch: 26 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.6556 - accuracy: 0.5435 - val_loss: 0.9253 - val_accuracy: 0.3333\n",
            "Epoch 28/50\n",
            "Epoch: 27 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.6381 - accuracy: 0.6304 - val_loss: 0.9513 - val_accuracy: 0.3333\n",
            "Epoch 29/50\n",
            "Epoch: 28 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 115ms/step - loss: 0.6506 - accuracy: 0.6087 - val_loss: 0.9414 - val_accuracy: 0.2500\n",
            "Epoch 30/50\n",
            "Epoch: 29 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6383 - accuracy: 0.6087 - val_loss: 0.8613 - val_accuracy: 0.2500\n",
            "Epoch 31/50\n",
            "Epoch: 30 Learning Rate: 0.01\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6368 - accuracy: 0.5652 - val_loss: 0.8211 - val_accuracy: 0.5833\n",
            "Epoch 32/50\n",
            "Epoch: 31 Learning Rate: 0.0091\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.6479 - accuracy: 0.5435 - val_loss: 0.8258 - val_accuracy: 0.5833\n",
            "Epoch 33/50\n",
            "Epoch: 32 Learning Rate: 0.00865\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6397 - accuracy: 0.5435 - val_loss: 0.7648 - val_accuracy: 0.5000\n",
            "Epoch 34/50\n",
            "Epoch: 33 Learning Rate: 0.0082\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6374 - accuracy: 0.5217 - val_loss: 0.7564 - val_accuracy: 0.2500\n",
            "Epoch 35/50\n",
            "Epoch: 34 Learning Rate: 0.00775\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 0.6417 - accuracy: 0.6087 - val_loss: 0.7622 - val_accuracy: 0.2500\n",
            "Epoch 36/50\n",
            "Epoch: 35 Learning Rate: 0.0073\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 0.6391 - accuracy: 0.6087 - val_loss: 0.7802 - val_accuracy: 0.2500\n",
            "Epoch 37/50\n",
            "Epoch: 36 Learning Rate: 0.00685\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6415 - accuracy: 0.6087 - val_loss: 0.8134 - val_accuracy: 0.2500\n",
            "Epoch 38/50\n",
            "Epoch: 37 Learning Rate: 0.0063999999999999994\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.6492 - accuracy: 0.6087 - val_loss: 0.8629 - val_accuracy: 0.2500\n",
            "Epoch 39/50\n",
            "Epoch: 38 Learning Rate: 0.0059499999999999996\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6545 - accuracy: 0.6087 - val_loss: 0.8652 - val_accuracy: 0.2500\n",
            "Epoch 40/50\n",
            "Epoch: 39 Learning Rate: 0.0055\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6444 - accuracy: 0.6087 - val_loss: 0.8341 - val_accuracy: 0.2500\n",
            "Epoch 41/50\n",
            "Epoch: 40 Learning Rate: 0.00505\n",
            "4/4 [==============================] - 0s 108ms/step - loss: 0.6400 - accuracy: 0.6087 - val_loss: 0.8379 - val_accuracy: 0.2500\n",
            "Epoch 42/50\n",
            "Epoch: 41 Learning Rate: 0.0046\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.6352 - accuracy: 0.6087 - val_loss: 0.8641 - val_accuracy: 0.2500\n",
            "Epoch 43/50\n",
            "Epoch: 42 Learning Rate: 0.004149999999999999\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6321 - accuracy: 0.6087 - val_loss: 0.8992 - val_accuracy: 0.2500\n",
            "Epoch 44/50\n",
            "Epoch: 43 Learning Rate: 0.0037\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.6323 - accuracy: 0.6087 - val_loss: 0.9176 - val_accuracy: 0.2500\n",
            "Epoch 45/50\n",
            "Epoch: 44 Learning Rate: 0.0032499999999999994\n",
            "4/4 [==============================] - 0s 114ms/step - loss: 0.6322 - accuracy: 0.6087 - val_loss: 0.9286 - val_accuracy: 0.2500\n",
            "Epoch 46/50\n",
            "Epoch: 45 Learning Rate: 0.0027999999999999995\n",
            "4/4 [==============================] - 0s 110ms/step - loss: 0.6314 - accuracy: 0.6087 - val_loss: 0.9348 - val_accuracy: 0.2500\n",
            "Epoch 47/50\n",
            "Epoch: 46 Learning Rate: 0.002349999999999999\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.6318 - accuracy: 0.6087 - val_loss: 0.9384 - val_accuracy: 0.2500\n",
            "Epoch 48/50\n",
            "Epoch: 47 Learning Rate: 0.001899999999999999\n",
            "4/4 [==============================] - 0s 111ms/step - loss: 0.6319 - accuracy: 0.6087 - val_loss: 0.9389 - val_accuracy: 0.2500\n",
            "Epoch 49/50\n",
            "Epoch: 48 Learning Rate: 0.00145\n",
            "4/4 [==============================] - 0s 109ms/step - loss: 0.6314 - accuracy: 0.6087 - val_loss: 0.9372 - val_accuracy: 0.2500\n",
            "Epoch 50/50\n",
            "Epoch: 49 Learning Rate: 0.0009999999999999992\n",
            "4/4 [==============================] - 0s 112ms/step - loss: 0.6313 - accuracy: 0.6087 - val_loss: 0.9346 - val_accuracy: 0.2500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "8GJVB63gqk0I",
        "outputId": "f90b2810-9cbb-4e9f-f296-fa7becbe5082"
      },
      "source": [
        "# list all data in history\n",
        "print(hist.history.keys())\n",
        "# summarize history for accuracy\n",
        "plt.plot(hist.history['accuracy'])\n",
        "plt.plot(hist.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU1fnA8e+bfSE7hCUk7LLvYRMXFLWA+4p7sbZU69pqq7a/Vmtra7VVamtVrFRtXaq4YQUXFEUQkCD7jqwJkEBCFsg+c35/nAkGCJBl7kxm5v08zzyTzL1z77kwmfee7T1ijEEppVToCvN3AZRSSvmXBgKllApxGgiUUirEaSBQSqkQp4FAKaVCnAYCpZQKcRoIlGokEXlRRH7fyH23i8g5LT2OUr6ggUAppUKcBgKllApxGghUUPE0yfxcRFaJyCEReUFE2ovIHBEpE5G5IpJSb/+LRGStiBSLyOci0rfetqEi8o3nff8FYo461wUissLz3q9EZFAzy/wjEdkiIkUiMktEOnleFxF5UkQKRKRURFaLyADPtkkiss5TtjwRubdZ/2BKoYFABafLgXOBU4ALgTnAL4F22M/8nQAicgrwGnC3Z9ts4H0RiRKRKOBd4N9AKvCm57h43jsUmAH8GEgDngNmiUh0UwoqImcDfwSuAjoCO4DXPZvPA87wXEeSZ59Cz7YXgB8bYxKAAcBnTTmvUvVpIFDB6G/GmHxjTB7wJbDEGLPcGFMJvAMM9ew3GfjAGPOJMaYG+DMQC5wKjAYigWnGmBpjzExgab1zTAWeM8YsMca4jDEvAVWe9zXFdcAMY8w3xpgq4AFgjIh0BWqABKAPIMaY9caYPZ731QD9RCTRGHPAGPNNE8+r1GEaCFQwyq/3c0UDv7fx/NwJewcOgDHGDewCMjzb8syRWRl31Pu5C3CPp1moWESKgUzP+5ri6DIcxN71ZxhjPgP+DjwNFIjIdBFJ9Ox6OTAJ2CEiX4jImCaeV6nDNBCoULYb+4UO2DZ57Jd5HrAHyPC8Vier3s+7gEeMMcn1HnHGmNdaWIZ4bFNTHoAx5iljzHCgH7aJ6Oee15caYy4G0rFNWG808bxKHaaBQIWyN4DzRWS8iEQC92Cbd74CFgG1wJ0iEikilwEj6733eeAWERnl6dSNF5HzRSShiWV4DbhJRIZ4+hf+gG3K2i4iIzzHjwQOAZWA29OHcZ2IJHmatEoBdwv+HVSI00CgQpYxZiNwPfA3YD+2Y/lCY0y1MaYauAyYAhRh+xPervfeHOBH2KabA8AWz75NLcNc4NfAW9haSA/gas/mRGzAOYBtPioEHvdsuwHYLiKlwC3YvgalmkV0YRqllAptWiNQSqkQp4FAKaVCnAYCpZQKcRoIlFIqxEX4uwBN1bZtW9O1a1d/F0MppQLKsmXL9htj2jW0LeACQdeuXcnJyfF3MZRSKqCIyI7jbdOmIaWUCnEaCJRSKsRpIFBKqRAXcH0EDampqSE3N5fKykp/FyVoxMTE0LlzZyIjI/1dFKWUw4IiEOTm5pKQkEDXrl05Mlmkag5jDIWFheTm5tKtWzd/F0cp5bCgaBqqrKwkLS1Ng4CXiAhpaWlaw1IqRARFIAA0CHiZ/nsqFTqCJhCEPFcNlBeBZpNVSjWRBgIvKC4u5h//+EeT3zdp0iSKi4u9U4jyQijeATXl3jmeUipkaCDwguMFgtra2hO+b/bs2SQnJ3unELVV9rm8yDvHU0qFjKAYNeRv999/P99++y1DhgwhMjKSmJgYUlJS2LBhA5s2beKSSy5h165dVFZWctdddzF16lTgu3QZBw8eZOLEiZx22ml89dVXZGRk8N577xEbG9v4QtR6OnYrDkBSBojGeKVU4wRdIPjt+2tZt7vUq8fs1ymRBy/sf9ztjz76KGvWrGHFihV8/vnnnH/++axZs+bw0MsZM2aQmppKRUUFI0aM4PLLLyctLe2IY2zevJnXXnuN559/nquuuoq33nqL66+/vnEFNMbWCMKjwVUFlSUQm9Ls61VKhRa9bXTAyJEjjxh//9RTTzF48GBGjx7Nrl272Lx58zHv6datG0OGDAFg+PDhbN++vfEndNeCcUF8WwiL1OYhpVSTBF2N4ER37r4SHx9/+OfPP/+cuXPnsmjRIuLi4hg3blyD4/Ojo6MP/xweHk5FRUXjT1jXPxARA3EpcLDAjiIK11nBSqmT0xqBFyQkJFBWVtbgtpKSElJSUoiLi2PDhg0sXrzY+wWo6x+IiIZYT5NTxQHvn0cpFZQcqxGIyAzgAqDAGDOgge3XAfcBApQBtxpjVjpVHielpaUxduxYBgwYQGxsLO3btz+8bcKECTz77LP07duX3r17M3r0aO8XoLYKEAiPAhGIjLPNQ23SvX8upVTQEePQBCQROQM4CLx8nEBwKrDeGHNARCYCDxljRp3suNnZ2ebohWnWr19P3759vVTyAFS41XYSp3v+DQ7tg5JcaNsbouKafdiQ/3dVKoiIyDJjTHZD2xxrGjLGzAeO22tpjPnKGFPXfrEY6OxUWYJebaVtFqoTkwIIVGinsVLq5FpLH8HNwJzjbRSRqSKSIyI5+/bt82GxAoBxg6vadhTXCY+AmETbT2Dc/iubUiog+D0QiMhZ2EBw3/H2McZMN8ZkG2Oy27VrcO3l0FVbDZgjawQAcWl2WGlVw53YSilVx6+BQEQGAf8ELjbGFPqzLAHLVW/oaH3RCRAWYXMQKaXUCfgtEIhIFvA2cIMxZpO/yhHw6oaOhh9VI5AwO7u4shRcJ855pJQKbU4OH30NGAe0FZFc4EEgEsAY8yzwGyAN+Icn933t8Xq01QnUVtk7//AG/itjU+0IosoDEK9Nakqphjk5augaY0xHY0ykMaazMeYFY8yzniCAMeaHxpgUY8wQzyNkgkCbNm0A2L17N1dccUWD+4wbN46jh8kebdq0aZSXFh+uDRyT1joqDiJiNeWEUuqE/N5ZHMo6derEzJkzm/3+adOmUV5WDJE2EDSY1jou1a5RUKPLTiqlGqaBwAvuv/9+nn766cO/P/TQQ/z+979n/PjxDBs2jIEDB/Lee+8d877t27czYICda1dRUcHVV19N3759ufTSS4/INXTrrbeSnZ1N//79efDBBwGbyG737t2cdcXNnHXRtYBNa71//34AnnjiCQYMGMCAUWcx7flXoKac7du307dvX370ox/Rv39/zjvvvKblNFJKBaWgSzrHnPth72rvHrPDQJj46HE3T548mbvvvpvbbrsNgDfeeIOPPvqIO++8k8TERPbv38/o0aO56KKLjrsW8DPPPENcXBzr169n1apVDBs27PC2Rx55hNTUVFwuF+PHj2fVqlXceeedPPHEX5j35nO07THsiGMtW7aMf/3rXyxZsgTjqmXUiGGcOf57pHTu1bJ010qpoKQ1Ai8YOnQoBQUF7N69m5UrV5KSkkKHDh345S9/yaBBgzjnnHPIy8sjPz//uMeYP3/+4S/kQYMGMWjQoMPb3njjDYYNG8bQoUNZu3Yt69atsxvq0oMcNXR0wYIFXHrppcTHx9MmMYnLJo3ny4VfAS1Md62UCkrBVyM4wZ27k6688kpmzpzJ3r17mTx5Mq+88gr79u1j2bJlREZG0rVr1wbTT5/Mtm3b+POf/8zSpUtJSUlhypQp9Y5TFwiiTnwQCQe3C2hhumulVFDSGoGXTJ48mddff52ZM2dy5ZVXUlJSQnp6OpGRkcybN48dO3ac8P1nnHEGr776KgBr1qxh1apVAJSWlhIfH09SUhL5+fnMmfNdJo6E+DjKymuPWZby9NNP591336W8vJxDhw7xzpxPOX3kYC9fsVIqWARfjcBP+vfvT1lZGRkZGXTs2JHrrruOCy+8kIEDB5KdnU2fPn1O+P5bb72Vm266ib59+9K3b1+GDx8OwODBgxk6dCh9+vQhMzOTsWPHHn7P1OuvZMK1t9Apswvz5s07/PqwYcOYMmUKI0eOBOCHN17L0H692F7lwIUrpQKeY2monaJpqD2MgT2r7PKUSRkn3vdgPpTutp3eYY2P/SH576pUkPJLGmrlMFc14D422VxDwj19CK4aR4uklApMGggC1eF1ipsSCKqdK49SKmAFTSAItCauFqs9TtbRhjQjEITcv6dSISwoAkFMTAyFhYWh9eXlqrSjhRrT5h8WAUijA4ExhsLCQmJiGhFklFIBLyhGDXXu3Jnc3FxCavWygwV29bHiDY3bv7QIwssgvrRRu8fExNC5s64eqlQoCIpAEBkZSbdu3fxdDN968krIGgOXP9+4/V/6hU0898NPnC2XUirgBEXTUMipLoeSXZDWs/HvScqy71FKqaNoIAhERd/a57ZNCQSdoWyvZ41jpZT6jgaCQFS4xT6n9Wr8e5IzAQNlux0pklIqcGkgCET76wJBj8a/J8nT8VuszUNKqSNpIAhEhZshsTNExTf+PUmZ9rkk15kyKaUClgaCQLR/c9P6BwASPfmItMNYKXUUDQSBxhjbR9CUEUMAkTEQn66BQCl1DA0EgeZgAVSVNq2juE5ypjYNKaWOoYEg0BRuts9NbRoC22GsncVKqaNoIAg0zRk6WifJUyMIpZxMSqmTciwQiMgMESkQkTXH2d5HRBaJSJWI3OtUOYLO/s0242jdKKCmSMqE2gooL/R+uZRSAcvJGsGLwIQTbC8C7gT+7GAZgk/JLvuFHtaM/7q6uQTaYayUqsexQGCMmY/9sj/e9gJjzFJAl81qivIiiG/XvPcm61wCpdSxAqKPQESmikiOiOSEVKrphpQXQlxq895b15ykHcZKqXoCIhAYY6YbY7KNMdnt2jXzbjhYlBdCXFrz3hubApFxWiNQSh0hIAKB8jCmZYFAxDNyaKd3y6WUCmgaCAJJVSm4a5sfCMB2GGuNQClVj2MrlInIa8A4oK2I5AIPApEAxphnRaQDkAMkAm4RuRvoZ4xp3FqKoahu2GdLAkFyJuxd5Z3yKKWCgmOBwBhzzUm27wV0UdymKPcMwmppjeDQPqipgMhY75RLKRXQtGkokHijRnA4HXVey8ujlAoKGggCyeFA0Mzho1AvEGiHsVLK0kAQSLxSI6ibXawdxkopSwNBICkvhLBIiE5o/jESO4GE6aQypdRhGggCSd0cApHmHyM8EhI6ao1AKXWYBoJAUl7UsmahOkmdNfGcUuowDQSBpCV5hupLytRAoJQ6TANBIGlJeon6kjrb4aNud8uPpZQKeBoIAok3A4G7Bg7mt/xYSqmAp4EgULhdUHHAO4EgOcs+a4exUgoNBIGjsgSM23s1AtB+AqUUoIEgcHhjMlmdw7OLNRAopTQQBA5vpJeoE5MI0UnaNKSUAjQQBA5v1gjANg/p7GKlFBoIAoe3A0FyptYIlFKABoLA4USNQPsIlFJoIAgc5YUQEQtRcd45XlImVBZDVZl3jqeUClgaCAKFt/IM1dF01EopDw0EgcJbeYbq1A0h1Q5jpUKeBoJA4a30EnWSdS6BUsrSQBAovB0I2rS3i9wU7/DeMZVSAUkDQaDwdiAIC4eUrlC0zXvHVEoFJA0EgcBVY3MNeTMQAKR2h6Kt3j2mUirgaCAIBBUH7LM3O4sB0nrYQGCMd4+rlAoojgUCEZkhIgUisuY420VEnhKRLSKySkSGOVWWgOftyWR1UrtDTbmuS6BUiHOyRvAiMOEE2ycCvTyPqcAzDpYlsDkWCLrZZ20eUiqkORYIjDHzgaIT7HIx8LKxFgPJItLRqfIENCdrBKCBQKkQ588+ggyg/iD2XM9rxxCRqSKSIyI5+/bt80nhWhWnAkFSFoRFaCBQKsQFRGexMWa6MSbbGJPdrl07fxfH97y5FkF94RGQ3AUKv/XucZVSAcWfgSAPyKz3e2fPa+po5UUQlQAR0d4/tg4hVSrk+TMQzAJu9IweGg2UGGP2+LE8rZe38wzVl9rdTirTIaRKhawIpw4sIq8B44C2IpILPAhEAhhjngVmA5OALUA5cJNTZQl43p5VXF9qd6gug0P7oU0INrsppZwLBMaYa06y3QC3OXX+oFJeCHFtnTl2/ZFDGgiUCkkB0Vkc8ry9FkF9aT3ss/YTKBWyNBAEAicDQVImSDgU6cghpUKVBoLWrrbKtuE71VkcEWXXJtAagVIhSwNBa1fumZztVI0AdAipUiFOA0Fr59Ss4vpSu0OhZiFVKlRpIGjtfBIIekBVyXfprpVSIUUDQWvnqxoBaKoJpUKUBoLWzpeBQPsJlApJGghau7rO4tgU586R0gUQDQRKhSgNBK1deSHEJNtMoU6JiLbzCTQQ+M+ip+GVK2HnEn+XRIUgB79dlFc4mWeovtRuGgj8ZduX8NGvICwcNn8Mp0yAs38NHQb4u2QqRDSqRiAid4lIoidT6Asi8o2InOd04RS+CwR1C9kr3yovgren2n6an62H8b+BHYvg2dPgrR/ZzLBKOayxTUM/MMaUAucBKcANwKOOlUp9x2c1gu5QUaRDSH3JGJh1BxzaB1fMgDbpcPo9cNcKGHsXrH8f/p5taws6x0M5qLFNQ+J5ngT82xizVkTkRG9QXlJeBB0GOX+e+iOHMoY7fz4FOS/Ahv/B9/4AnYZ893pcKpz7Wxh1C3z8f7Do7zBoMnT0wedAeUdZPuxdBXtWQskuqK0GV5VNGeOqsT8bA/FtIT7d3gS0SYc27e1zcheITfZZcRsbCJaJyMdAN+ABEUkA3M4VSx3m5KI09R0OBNs0EPhC/lr48JfQ81wYdWvD+yR2tE1Fa2bCriUaCFqr2mrY9gXsXOz58l8FB/d+tz2+HUTEQHiUHZgRHgnhntUGdy+HgwVQffDY48amQEo3239X95yRDel9vH4JjQ0ENwNDgK3GmHIRSUUXknFedTnUVvimaSilq33WfgLnVZfDzJshJgkueQbCTtBCm5wFiRmw4ysY+SPflVGdWE0lfPsprJsFG+fYmfkSDu16Q/dx0HGwDdwdBtr/55OpPmQDwsECG0QO7IAD2+yNWd4yWPsuGBec9lM45yGvX05jA8EYYIUx5pCIXA8MA/7q9dKoI/liMlmdyFhI7KyBwBc+/hXsWw/Xv33yxYBEIGu0DQTG2N+Vfxhjv/TXzIRNH9m7+Jhk6Hsh9LsIup1h/46aIyre3vGndmt4u6vGNjFFxDS//CfQ2EDwDDBYRAYD9wD/BF4GznSkVMryZSAA+yHUNBPOWjcLcmbAqXdCz/GNe0/WGFjzFhTv9Ez+Uz63ewXMuQ92LbarBQ68AvpdDF1Pt009TguP/K751gGNDQS1xhgjIhcDfzfGvCAiNztWKmX5PBB0hw0f+OZcocgY2/nbYZCdJ9BYWWPs885FGgh87dB++PRh+OZl+3d40d9g8LXOTvD0g8ZeTZmIPIAdNnq6iIThWYheOcgXaxHUl9odyvdDZUnj2jVV0+zfDMU74IIn7YJAjZXeF6KTbCAYfLVz5VPfcdXA18/D549CzSEY/RM48xc+HcnjS40NBJOBa7HzCfaKSBbwuHPFUkC9GoEPRg3BkSOH6g9nVN6xZa597nlO094XFg6ZI+2oFOW8/Zvhv9fDvg3QYzxM+KPtBA5ijZpQZozZC7wCJInIBUClMeZlR0umbCCQMNsh5Qu6kL2ztsyFtr3tSKCm6jLGfjHV1RKVMwrWw78m2Saha16H698K+iAAjU8xcRXwNXAlcBWwRESucLJgChsIYlNPPLzQm3QIqXNqKmDHwqbXBuoc7ifQWoFj9q6GF8+3N183zYbeE0NmlFZjm4Z+BYwwxhQAiEg7YC4w06mCKXyXXqJOVDwkdNRA4ITtC6G2svEjhY7WaZidkLRzEfSZ5N2yKTux6+VL7N/A99//rnYcIhp7qxlWFwQ8ChvzXhGZICIbRWSLiNzfwPYuIvKpiKwSkc9FpHMjyxMafB0IQBeyd8qWuRARC13GNu/9kTHQaagNBMq7cnPgpYshOtHWBEIsCEDjA8GHIvKRiEwRkSnAB8DsE71BRMKBp4GJQD/gGhHpd9RufwZeNsYMAh4G/tiUwge98iLfdRTX0XTUztjyCXQ9zX6hN1fWGDuevbrce+UKdTsW2ZpAXKoNAnXNoyGmsZ3FPwemA4M8j+nGmPtO8raRwBZjzFZjTDXwOnDxUfv0Az7z/Dyvge2hzS81gh5wMB+qGsh9opqnaBsUbml+/0CdrDHgroHd33inXKEubxn853JI6GCDQHKmv0vkN43uhTTGvGWM+Znn8U4j3pIB7Kr3e67ntfpWApd5fr4USBCRY775RGSqiOSISM6+ffsaW+TAZoz/mobA5jlR3vHtp/a5pYEgc6R93qHNQy1mDMz+uZ0vM+UDSOzk7xL51QkDgYiUiUhpA48yESn1wvnvBc4UkeXYdBV5gOvonYwx040x2caY7HbtTpKbJVhUldm7P38FAm0e8p4tn9q0wi1te45LhfR+2k/gDetn2RrB2b+ChPb+Lo3fnXDUkDEmoQXHzgPq17U6e16rf/zdeGoEItIGuNwYU9yCcwYPX6eXqFOX9EpzDnlHbTVs/cLOCPbGUMSs0bDqTXC77EQz1XSuWps2ol1fGHyNv0vTKjg5QH0p0EtEuolIFHA1MKv+DiLS1pOuAuABYIaD5Qksvk4vUSc6wS6UoTWCk9u9HJ470+afP55di22KgpY2C9XJGgPVZZC/xjvHC0XL/237bMb/RoOph2OBwBhTC9wOfASsB97wrGz2sIhc5NltHLBRRDYB7YFHnCpPwPFXjQDsTMo9K3x/3kBSWw3v/sT+O713m73LbMiWuRAWaVMUe4NOLGuZ6nKbPyhztJ0wpgBnawQYY2YbY04xxvQwxjziee03xphZnp9nGmN6efb5oTGmysnyBBRf5xmqr9uZdpblof2+P3eg+PIvULAOsn9gV6Va/HTD+2351KaHiG7jnfMmZ9p1I7SfoHmWPGsXfjnnoZCZNdwYPspdoJrMnzWCHmfZ562f+/7cgSB/LXz5Zxh4FZz/BPS5AOb94dh+ldI9tgnHW81CdbJG25FDuqB905QXwYJpcMpEG5zVYRoIWqvyQtukEN2S/vpm6jTUDqvTQHAsV61tCopJhgmP2rvKSY/b9A//u/vIL2dvDRs9WpcxnuUMt3v3uMFuwRNQVWr7BtQRNBC0VnWL1vuj+hoWbtu0t36ud51HW/y07SSe9DjEe2priZ3g3N/Ctvmw4pXv9t0y1+ZuSj96Qn0LaT9B05XkwpLpdpRQey//fwQBDQStlT8mk9XX/Sy7RqoOI/3O/i22CajPBdD/0iO3DZsCWafCR7+Csnxbc/h2nk0y5+1g3q6vrbHt/Mq7xw1m8/4IGDjrAX+XpFXSQNBalRf5ORCMs89b5/mvDI2xbyO8dg0sfwVqKp07j9sNs+6AiGg4/y/HfrmHhcFFT0FNOXx4n52sVFns/WahunNljg6+GoGr1q7LvH0BrHjNrhBWW93y4xZsgJWvwsipzVsLIgQE18KbwaRsD3Qc5L/zp3a3fzTfzoORP/JfOU7EVQNv/dCOcNo4G+Y+CNk325E83p4tmvOCvQO/+Gmbm6YhbXvZ5Qw/+z2U5Nm89t3HebccdbJGw+aP7Miu+LbOnMMXdiyCeY/YJTxL8sAclVigqhROv6f5x3e7Yc4vIKpNy44T5LRG0Brt22hz/TQ3ZbE3iNjmoe1fHn+MvL99+Rc7dHPyv+HG9yBjOHzxKEwbAO/cCntWeuc8xbtg7kPQ42wYct2J9z31LkjvD7lfQ+cREJvinTIcrcup9nnzx84c31c+/4MdWZU5Gk77KVz4FNzwLtzxjW2C++JxW0torkV/g21fwLkP+2codoDQQNAarZ5p7yb7XeLfcvQ4y96RtcZsl7tXwPzH7RDOvhfaO+9r/wu3L4PhU2Dde/DcGbD23Zaf68u/gLsWLph28vb+iCi46G/2/++U77X83MfTeSS06wNf/S1wO/QP7LAd7KN/Apc/D+N/DcO/bz93aT2+G5X1YTPb9fO+sakk+l5oPxPquDQQtDbGwJqZ0PV0/yfD6nYmILZ5qDWprYJ3b4W4tjDpsSO3te1pR/T8bB2k9YTFz7TsXFVlsPpNGHA5pHRp3Hs6D4fbc2DM7S0794mEhdk76IJ1gVsrWPEqIMfP95OcCWf8HDb8DzY18RqrDsJbN0Ob9raWoZPHTkgDQWuzZ4XN8zOwFSwJHZcKHQe3vg7jzx+1X4AX/e34TS+xyTDsRpvrZ9/G5p9r9ZtQfRCG39S096X1sB3LThpwOSRlwoInnT2PE9xuGwi6jzvxOgBjboe2p8Ccn9t1nxtrzi/sOhCXTdcmoUbQQNDarJ5pJ5L1vdDfJbF6nAW5S+2dcWuQmwMLp8HQ6+GU80687+BrICwCvnm5eecyBnJmQPuB0Dm7ecdwUngknHqHTTcRaGsUbJ8PJTvt/+OJRETBpD/byXMLpjXu2Ktn2vkcZ9xrV4VTJ6WBoDVxu2HtO9DrXOc6GZuq+1m2fXz7Qn+XxN4RvnMLJHSC7/3h5Pu3SbeJxVa+3rxhiHnf2BFJ2VNab9PC0BvsMOOFjfySbC2W/8fOhehzwcn37X6mrf0sePLkWXEP7ID//dR21J95skUUVR0NBK3JzkVQmmc/9K1F1mi76HpraB767PdQuBku/rv9EmmMYd+H8v2waU7Tz5czAyLjbYd0axUVB6NugU0f2hxIgaDiAKybBQOvbPwazuc9YtN4zP7F8TvHXbV2ODHA5f+0NSbVKBoIWpM1MyEyrnWlx42ItkMV/dlhbIytKS162s4RqEuK1xg9zobEjKY3D1UUw5q3bF9NTGLT3utrI35oA9bCv/q7JI2z5i1wVZ28Wai+xI52VvCWT2zncX3Vh+zkug9+aoftXvBkyC5C31w6oay1cNXYoY69J0JUvL9Lc6Tu4+CTX0Ppbt+u7WqMzXc07xHbT5HeD879XdOOERZuv3C+eMzOB2jsAuWr/gu1FZDdxE5if4hLteVc/Ayc9avGj27yl+Wv2LkWHYc07X0jf2zfO+d+OJgPectt3qd968G47T7ZP2gdAy0CjNYIWoutn0NFEQxohR9if6Sl3rEIXrwA/n2JDUAX/hV+PL95ef3rJoHVTwh3Ij1aRzwAAB48SURBVMZAzr9sFtZOQ5t+Pn8Yc5udu7Do7/4uyYnlr7XzUoZe3/R+l/AIm96jNBc+uMc29yV2skNMr3kd7tloawOqybRG0Fqsecu2e/cc7++SHCu9P8S3s81DQ6519lz56+Dj/7MpnNu0h4mP2Xb+xrYlNySli63VLP+P/dI42fKEOxfbu8yL/tb8c/paYie7LvI3L8MZv4A27fxdooYtf8WOihvUzH6XLmPgloW2uS4ps/V24gcYrRG0BjUVsP5/0Pci58eeN0eYJ2eO02mpD+2Hly+y1f1zfwd3roBRP25ZEKgz7EabTbUxtZpl/4LoxNbVad8YY++yk+2+fu7I142B/Zth2Us2GZ6/1FbbJrfeE1qWH6nDAJsHS4OA12iNoDXY/LFdkLw1t212P8tOripYB+37e//4xsD7d0FlCUz93Pvn6HM+xKbaO+YT1brKi2xfzbAbW19fzcm07WXnn3w9HXpPsk0w2xfAjq9smzpA295w+9f+Kd/mj+wIrqE3+Of86rg0ELQGq2dCfLpNK9FadR9nn7+d50wgWPmaHQ1y7u+cOX5EtJ1g9vX0E2fsXPGqHdESCJ3EDTntblg/C5739OskZthUIV3H2jH2C56wa0yk9fB92Zb/B9p0gB6tsPkzxGnTkL9VlsKmj+xCJydru/anpAw71d+J+QQHdtjx4V3G2k5Ppwy7Adw1doJZQ4yxzUKZo5wJRr6QMRwu+rt93LkCfrrWJnQbPuW74LbhA9+Xq2wvbP4EhlxjO31Vq6KBwN82fGDvQFtzs1CdUybAt5/Bti+9d0y3yyaQA7jkGWeDYXpfm7Xzm5cb7uvY/iUUbml6XqHWZtgN9pHa7ch29OQs6DDQrt3gaytft2sNDGnC3AHlMxqa/W3NTPsH2nmEv0tycmf+ws5gnXmTHcrpjTkFi56GHQvh4n/4Zvz7sBth1u02GEiY/eIv+tY2lxRttYvS9/dz+m8n9T4f5j/m2wVtqg/Bkmdtja9tT9+cUzWJ1gj8qXinbXMfcHlgjICIToDJ/4HqcnhzSsuXEcxfC5/9zuabcXpYap3+l0JUArx/pw0Ii562Sxkmd7EzdK9/GyJjfVMWf+gzyU6+2vSh78658K92xb3xD/runKpJHK0RiMgE4K9AOPBPY8yjR23PAl4Ckj373G+M8UO91U/m/cHmQxnRSpeCbEi73jbXz8yb7GzjiX9q3nFqq+DtqfYO/MK/+i4QRreBKe/bO+K0HpCUFVpt1h0G2fH3G2Y3LcVDc5XkwcKnoP9lkDXK+fOpZnHsL0BEwoGngXOBXGCpiMwyxqyrt9v/AW8YY54RkX7AbKCrU2VqVfLX2nbTU++wHbGBZMBlNuXD4n/YJq2m9m8YY1eOyl8D1/zX92vuBspsYSeI2DQm3/zb1uyi4pw936e/tTWQc3/r7HlUizjZNDQS2GKM2WqMqQZeBy4+ah8D1GX0SgJ2O1ie1uXTh+3syNN+6u+SNM+5D0PWGJh1BxSsb/z7yovgjRttKoThN9nJRcq3ek+yeZScziibu8xOIBtzm+0HU62Wk4EgA9hV7/dcz2v1PQRcLyK52NrAHQ0dSESmikiOiOTs27fPibL61o5Fto127N2Bu3pSeCRc+SJEtYH/Xm+HwZ7M5rnwjzGwcQ6c81ubN0b5XtfTIDrJNg85xRj46AE7P+b0nzl3HuUV/u4svgZ40RjTGZgE/FtEjimTMWa6MSbbGJPdrl0rzaHSWMbA3AchoaPNIx/IEjrYYFC0zbb371lpc8IfrbocPrgXXrncLrgzdZ6d+NSa500Es/BIu/jRpg/t8F0nrH0bdi2xC9JHJzhzDuU1TvaS5QH1c/529rxW383ABABjzCIRiQHaAgUOlsu/Ns6xfyAXTHO+fdYXuo6F7z0CH95vs0FGxEKnIXZiU+ds2xk8++d2QZkxt8PZv/ZO7iDVMn3Ot0OXd31tE7l5U00lfPKQnbNQl/lVtWpOBoKlQC8R6YYNAFcDR48R3AmMB14Ukb5ADBAEbT/H4XbZvoG0nsGVb2X0rbbdOXepTWqWuxS+fv67lMiJGXDjLLvkoGodep5js4Bu/MD7gWDx03Y94kve11pfgHAsEBhjakXkduAj7NDQGcaYtSLyMJBjjJkF3AM8LyI/xXYcTzHGyfSWfrbydZve+MqXgm/IYkoX+6gbQVRbDfmr7USt1rQGs7JiEqHbGXZm+7m/897w3bJ8+PIJO3Gt2xneOaZynKPfRp45AbOPeu039X5eB4x1sgytRk2lnTfQaRj0O3rwVBCKiLLNQxnD/V0SdTx9JtkFXvZthPQ+3jnmZw/bOSLnNXElOeVX/u4sDh1Ln7crK53zUGDMIlbBr/ck+7zRC0nojIHPHrEZRkff6p/spqrZNBD4QkUxfPkXu5C6tpOr1iKxk51c19JhpMbAR7+yOYyG3mBvdlRA0UDgC3Pus+Psz3nI3yVR6ki9z4e8HJsmujncLvjf3baDeNQtcOFT2kEcgDQQOG31TFj1us3c2XGwv0uj1JH6nG+fN85p+ntdtfDOLbDsRTj9HpjwqF3WVAUc/V9zUvFO+N/PbA780+/1d2mUOlZ6X0jpCmvfaXgy4PHUVsGb34fVb8D439iH9n0FLA0ETnG77Gxb44bLpgffcFEVHERg0NWw7Qt4agh89fcTpwtx1dqFiV650i4tOvExWxtQAU2/nZyy4AnYuQgufc6uFKVUa3XmfbbZctHf4eNfwRd/sgv4jLoFkjPtwjJbPrUrm236ECoOQEQMXPy0b1JZK8dpIHBC7jKY90e74Mygyf4ujVInFhZm5xT0mQR539jFehY/Yx+ds20OqdpKmy6k90Q77LTH2XZtBxUUJNAm8mZnZ5ucnBx/F+P4qg7Cs6eBuxZuWQCxyf4ukVJNV7wLvn4Otn4BXU61ncpZp2oTZwATkWXGmOyGtun/qrfNuQ+Kd8CUDzQIqMCVnAnn/d7fpVA+op3F3rTuPVjxHzjtZ/YuSimlAoAGAm85tN8OFe04BMbd7+/SKKVUo2nTkLfMvhcqS+D779uFP5RSKkBojcAb1r5rJ+SMuw/a9/N3aZRSqkk0ELTUof02lW/HITA2QBeiV0qFNG0aaqnZP/c0Cc3SoXVKqYCkNYKWWPeeXaR73H3Qvr+/S6OUUs2igaC5DhV6RgkNhrF3+7s0SinVbNqW0VyHRwnN0lFCSqmApjWC5ljxmm0SOlObhJRSgU9rBE2xZyXMfQi+/cwuyn6aNgkppQKfBoLGKNoG8x6B1W9CbAqc9wiM+KE2CSmlgoIGghM5uA/mPw45MyAswi7AceqdmkxOKRVUQioQFB6sIq1N9Ml3rD5kc7Iv/CvUVNhFOs68DxI7Ol9IpZTyMUc7i0VkgohsFJEtInJMJjYReVJEVngem0Sk2KmyfLx2L6c/No/Xv97JcddgcNXahbifGmabgnqcBbctgQunaRBQSgUtx2oEIhIOPA2cC+QCS0VkljFmXd0+xpif1tv/DmCoU+UZ2DmJIZnJ3P/2auauL+DRywfStq52YAxsnGM7gvdvhMxRcNXLkDXKqeIopVSr4WTT0EhgizFmK4CIvA5cDKw7zv7XAA86VZiOSbH85+ZRzFi4jcc+2sCUJ9/iD6NdDArbDls/h7wcSOsJk1+xqzGJUFnjIio8jLAwcapYSinld04GggxgV73fc4EGb7FFpAvQDfjsONunAlMBsrKymleagvWErfovP9yzkiltlhNReQAWgotwJL0PYec/QX7Pq8jZdZCl768jZ0cR63aX0ik5lutGdWHyiExS46Oad26llGrFWktn8dXATGOMq6GNxpjpwHSwaxY36wxF2+Crv0F6XyL6XkBN+0G8ujOFPy6PIK00ifB5ws635gMQExnG0MwUfnxmD5bvPMCfPtzAk3M3ccHAjlw/pgtDM5MRaV21BLfbsH5vKYeqXFTW2EdVrZvKGhfGwPCuKfRop4uNK6WO5WQgyAMy6/3e2fNaQ64GbnOwLNDzHHggDyJjAIgEvj8aemcX8vhHG2nbJoobx3Qhu2sq/TslEhn+XT/65vwy/r14B29/k8fby/Po3ymR8/p1ICU+kqTYSBJjIkmMtT+nJ0aTGOPb+QUut+Hu/67g/ZW7T7hft7bxjO+Tzvi+7RnRNYWIcJ1YrpQCOe4ImpYeWCQC2ASMxwaApcC1xpi1R+3XB/gQ6GYaUZjs7GyTk5PjQIlP7mBVLe8uz+M/i3ewYW9Zg/uEhwmjuqUycUAHvte/A+mJMY6WyRjDA2+v5vWlu7jtrB6M6d6WmMgwYiLDiY6wzzUuNwu27Gfu+gIWf1tItctNYkwEZ/VJ56fnnELXtvGOllEp5X8isswYk93gNqcCgefEk4BpQDgwwxjziIg8DOQYY2Z59nkIiDHGNGqhX38Ggvqqa92UVtZQUvHdo7Sihs35B5mzZg/f7juECGR3SWHCgI5MGNCBjORYr5bBGMPv/reeGQu3ccfZPbnnvN4nfc/BqloWbN7Hp+sL+HDNXjJSYpl1+2lERWjtQKlg5rdA4ITWEghOZnN+GbNX72XOmj2Haw/pCdH075RIv06J9O+URP9OiWSmxDV7VNKTn2zir59uZsqpXXnwwn5N7rf4dH0+N7+Uw+1n9eTe7508iCilApcGAj/btv8Qn20oYG1eCev2lLK54CAut/13T4iOYFT3NMb3Tees3ul0SGpcU9Lz87fyyOz1XJXdmUcvG9TsYHLvmyt5Z3keb996KoMzNXWGUsFKA0ErU1njYlN+GWt3l7Iqt4T5m/aRV1wBQL+OiTYo9Emnf6dEoiPCj3n/q0t28st3VnP+oI48dfVQwlswz6GkoobvPTmfhJgI3r/jNGIijz2fUirwaSBo5YwxbMo/yGcbCvhsQz7LdhzAU2EgNjKcpNhIkuPsqKT46AjmbSzgrN7pPHv9cK+07X++sYAp/1rKLWf24P6JfVp8PKVU63OiQNBa5hGENBGhd4cEendI4NZxPSgur2b+5v3sKiqnuLya4nLbGV1cUUPegQouGNSJx68Y5LUO3nG907l6RCbT53/Lef3bMywrxSvHVUoFBq0RKADKKmuYMO1LoiPDmH3n6dpEpFSQOVGNQMcMKgASYiL50+WD2LrvEH/+aKO/i6OU8iENBOqw03q15frRWbywcBsLNu/3d3GUUj6igUAd4YGJfclMieP6F5Zw2T8W8trXOymrrPF3sYKCy234dH0+G/aW+rsoAaGqtsHUY8oB2kegjlF0qJo3c3bx5rJcthQcJCYyjEkDOnJFdmdGd0sL2rTcBw5VU1nromOSd2eAH6qq5Y2cXcxYuI1dRRXERYXz3A3DOb1XO6+eJ9BVVLtYvLWQLzbt4/ONBewoKufSIRn87LxT6JwS5+/iBTwdPqqaxRjDil3FvLksl/dX7KasqpaM5FjOH9SRSQM7MrhzUqvLwtpcu4rKmfzcIg5Vu3jnJ6fS3QuZWveUVPDiV9t5bclOSitrGd4lhetGZTF9/la+3XeQv149lEkDj7/ynTGGN3Ny+XhdPnef04sBGUktLlNrs7u4gtmr9/DFpn0s2VZEda2bmMgwxnRPo2NyLDOX5YKBG8d04bazepKiqeCbTQOBarGKahcfrd3LeyvyWLBlPzUuQ0ZyLJMGduD8QZ0COijkFVcw+blFlFXWEh4mJMdG8s5PxpIU17wssvmllfzpww3MWrEbtzFMHNCRm0/vdnhYbklFDTe/uJRlOw/wh0sHcs3IY9fYyCuu4P63VvHl5v1EhYfhMoZbzuzOHWf3ataIro17y3jsww1Uu9zcMLoL4/u2b9FExJZwuQ3zN+/jlcU7+GxDAW4DPdPbMO6UdpzZux0juqYevsbdxRVMm7uJmctyiY+K4JZxPfjB2G7ERumotqbSQKC8qqS8ho/X7WX26j2Hg0LHpBiyu6YyLCuZYVkp9O2YGBCJ7PaWVDJ5+iKKDlXz6g9HU1Hj4rp/LmZUtzT+ddOII9KRn4zLbXhlyQ4e/3AjVS43143K4gdju5GZemyzRkW1i5+8sox5G/fxiwm9ufXMHogIbrfh1a938sfZ6zHA/RP7cOGgTjwyez0zl+XSo108j10xmOFdGjfXo6Sihic/2cS/F+8gISaCuMhwdpdUkpUax41junDViEyfpU3ff7CKN3J28eqSneQeqKBtmyiuys5k8ohMuqSdOAPupvwyHvtwI3PX55OeEM2kgR0Z3iWFEV1TG52WJdRpIFCOKSmv4ZP1+Xy2IZ/lO4vZU1IJQHREGAMz7DrRXdLiaJ8YQ4ekGDokxpDWJtpvd6P1FZRWcvX0xRSUVfHvm0cy1HPH/sbSXfzirVXcOKYLD188oFHHWru7hF++s4aVu4o5vVdbfnfxgJOm965xubn3zZW8t2I3U8/oznWjsrj/rdUs2lrIaT3b8sfLBh4RRL7YtI9fvr2a3SUVTDm1Kz//Xm/iohqeE+p2G2Yuy+VPH26gqLyaa0dmce95vUmIieDjdfnMWLCNnB0HiI8K58rsTK4Y3pkuaXEkHCcouNyGzQVlfLOjmG92HmDd7lJS4iPJSo0jKzWeLmlxZKXGkZkaR2WNi11F5ew6UM7Owgr7XFTO8p0HqHEZxnRP47rRWZzXr0OTbxaWbi/i759t4ettRVTU2M7kjORYRnRNYXjXVEZ1S6VXepuArZ06SQOB8pk9JRUs31nMNzsOsHxXMavzSqiudR+xT0SYkJ4QTY/0NvTrlMgATybWrmnxPuuI3n+wiqunL2Z3cQUv/2Ak2V1Tj9j+yAfreP7Lbfzu4v7cMKbrcY9TXl3LtLmbeWHBNlLiIvn1Bf24aHCnRn8Rud2G376/lpcW7SBMID4qgl+d35fJIzIbPMbBqloe+3ADLy/aQUZyLEOzkkmNjyIlLoq0NvY5MjyMZ774lpW7ihneJYXfXtS/wf6FVbnF/Gvhdv63ajc1Lvs9kBgTQUZKHBnJMWQkxxIfHcHqvBJW7CymrKoWgNT4KAZkJFFaUcOuonIKD1Wf8BrTE6LJTI1jSGYy14zMomd6y/tfalxu1u8pZen2AyzbUcTS7QfYV1YFQFp8FKO7pzG6RxpjuqfRo128BgY0ECg/crsN+w9VkV9SxZ6SCvJLK9lbWsme4ko25pexKb/s8JdQfFQ4fTsmkpESS3iYEC5CRLgQHiZEhNk7R7cxuNxHPtyez7CIIAKCfQ4TSGsTTaekGDokxdIxKYaOSTGICNc+v5jthYd48aaRjO6edky5XW7Dj17O4YtN+3jpppGc1qvt4W3GGNbuLuXjdfnMzNnF7pJKrhmZyX0T+pAc1/TOTGMMz36xlXV7SnlgYh86NWLdiq+3FTFt7ib2llRSeKiakoojh/i2S4jmgYl9uHRoxkm/BAtKK1myrYi84gp2F1eQd6CCvGL7OFRVS+8OiYeb/IZ3SaFLWtwRxyyrrGFnUTk7C20tIDYynM6pcWSmxNE5JdYns9SNMewsKmfJtiIWf1vIoq2Fh2un7RKiGZ6Vwint29CzfQKntG9Dt7bxDSZ0DGYaCFSrVV3rZnOBzcS6bncpa/JK2H+wCpcxuFyGWs+Xfa3nCz8izAaGMBEiwoQwz88ABoMxeB4GlzEUHqym1n3kZ1wEosLDmDFlBGN7tm2oWID9grv8ma/YW1LJW7eeyr6DVXy8Np9P1uWTV1xBmMCIrqnc+73ejDiqRuFrtS43B8prOODJTdWvUyJtolueSqzW5Q7IJU3rAsMiT1BYnVvC9sJDh5M5hocJXdJssAK+u7EwBrfnsyYihInnBgMIEyEsDKIjwomNDCc26shnEah1GWrcbmpdhlqXmxr3d8czBtyez2bdJzIyXIgMDyMyPIzoiLDDP4eHHXljEyb2/IMzkxnZrXmfNQ0EKmS53Yb9B6vYU1LJnpIK9pRUkl9axTl9049pDmrIrqJyLn56IUWe5o+oiDDO6NWW8/p3YHyfdNLaRDt9CcpLKmtcbNt/iE35ZWwpOMim/DL2lFQiIoQLh28wwuvdXLiN8TwAAy5jqKp1UVHtedS4KK92UeVp/hSByLAwIg5/wdtjhdUPKp4vdYOxgcPlprrWTbXLTY3LHF6rpCEtyRCsgUCpFli+8wBv5ORy5iltOb1XO+K9cKetgkvdl7c3BkG43AbjCT51zZ51wSgiTJrd1KZpqJVqgaFZKYdHFCnVEG+OgrPH8m3nduA1/imllPIqDQRKKRXiNBAopVSI00CglFIhztFAICITRGSjiGwRkfuPs89VIrJORNaKyKtOlkcppdSxHBs1JCLhwNPAuUAusFREZhlj1tXbpxfwADDWGHNARNKdKo9SSqmGOVkjGAlsMcZsNcZUA68DFx+1z4+Ap40xBwCMMQUOlkcppVQDnAwEGcCuer/nel6r7xTgFBFZKCKLRWSCg+VRSinVAH9PKIsAegHjgM7AfBEZaIwprr+TiEwFpnp+PSgiG5t5vrZAqK7KHqrXrtcdWvS6j6/L8TY4GQjygMx6v3f2vFZfLrDEGFMDbBORTdjAsLT+TsaY6cD0lhZIRHKON8U62IXqtet1hxa97uZxsmloKdBLRLqJSBRwNTDrqH3exdYGEJG22KairQ6WSSml1FEcCwTGmFrgduAjYD3whjFmrYg8LCIXeXb7CCgUkXXAPODnxphCp8qklFLqWI72ERhjZgOzj3rtN/V+NsDPPA9faHHzUgAL1WvX6w4tet3NEHBpqJVSSnmXpphQSqkQp4FAKaVCXMgEgsbkPQoGIjJDRApEZE2911JF5BMR2ex5DrpVVkQkU0Tm1ctbdZfn9aC+dhGJEZGvRWSl57p/63m9m4gs8Xze/+sZuRd0RCRcRJaLyP88vwf9dYvIdhFZLSIrRCTH81qLPuchEQjq5T2aCPQDrhGRfv4tlWNeBI6eoX0/8Kkxphfwqef3YFML3GOM6QeMBm7z/B8H+7VXAWcbYwYDQ4AJIjIa+BPwpDGmJ3AAuNmPZXTSXdhRiXVC5brPMsYMqTd3oEWf85AIBDQu71FQMMbMB4qOevli4CXPzy8Bl/i0UD5gjNljjPnG83MZ9sshgyC/dmMd9Pwa6XkY4Gxgpuf1oLtuABHpDJwP/NPzuxAC130cLfqch0ogaEzeo2DW3hizx/PzXqC9PwvjNBHpCgwFlhAC1+5pHlkBFACfAN8CxZ65PBC8n/dpwC8At+f3NELjug3wsYgs86TfgRZ+zv2da0j5mDHGiEjQjhkWkTbAW8DdxphSe5NoBeu1G2NcwBARSQbeAfr4uUiOE5ELgAJjzDIRGefv8vjYacaYPE/a/k9EZEP9jc35nIdKjaAxeY+CWb6IdATwPAdlum8RicQGgVeMMW97Xg6JawfwJGucB4wBkkWk7kYvGD/vY4GLRGQ7tqn3bOCvBP91Y4zJ8zwXYAP/SFr4OQ+VQNCYvEfBbBbwfc/P3wfe82NZHOFpH34BWG+MeaLepqC+dhFp56kJICKx2IWg1mMDwhWe3YLuuo0xDxhjOhtjumL/nj8zxlxHkF+3iMSLSELdz8B5wBpa+DkPmZnFIjIJ26YYDswwxjzi5yI5QkRewybyawvkAw9ik/u9AWQBO4CrjDFHdygHNBE5DfgSWM13bca/xPYTBO21i8ggbOdgOPbG7g1jzMMi0h17p5wKLAeuN8ZU+a+kzvE0Dd1rjLkg2K/bc33veH6NAF41xjwiImm04HMeMoFAKaVUw0KlaUgppdRxaCBQSqkQp4FAKaVCnAYCpZQKcRoIlFIqxGkgUMqHRGRcXaZMpVoLDQRKKRXiNBAo1QARud6T53+FiDznSex2UESe9OT9/1RE2nn2HSIii0VklYi8U5cLXkR6ishcz1oB34hID8/h24jITBHZICKvSP2ESEr5gQYCpY4iIn2BycBYY8wQwAVcB8QDOcaY/sAX2FnbAC8D9xljBmFnNte9/grwtGetgFOBuuyQQ4G7sWtjdMfmzVHKbzT7qFLHGg8MB5Z6btZjsUm83MB/Pfv8B3hbRJKAZGPMF57XXwLe9OSDyTDGvANgjKkE8Bzva2NMruf3FUBXYIHzl6VUwzQQKHUsAV4yxjxwxIsivz5qv+bmZ6mf+8aF/h0qP9OmIaWO9SlwhSffe916sF2wfy91mS2vBRYYY0qAAyJyuuf1G4AvPKuk5YrIJZ5jRItInE+vQqlG0jsRpY5ijFknIv+HXQUqDKgBbgMOASM92wqw/Qhg0/4+6/mi3wrc5Hn9BuA5EXnYc4wrfXgZSjWaZh9VqpFE5KAxpo2/y6GUt2nTkFJKhTitESilVIjTGoFSSoU4DQRKKRXiNBAopVSI00CglFIhTgOBUkqFuP8HRsrb1TZYM1MAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIE-GF0vgDpd"
      },
      "source": [
        "## Evaluation on Unseen Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ETUtjC0gq8ct",
        "outputId": "24919352-70ea-4f64-ff8e-dac0985e3b06"
      },
      "source": [
        "print(\"Evaluation on Unseen Dataset:\")\n",
        "\n",
        "x_test = np.concatenate((samples_unseen, resp_samples_unseen), axis=1)\n",
        "print(x_test[1].shape)\n",
        "\n",
        "model.evaluate(x_test, y_unseen)\n",
        "y_hat = model.predict(x_test)\n",
        "\n",
        "y_pred = np.argmax(y_hat, axis=1)\n",
        "y_true = np.argmax(y_unseen, axis=1)\n",
        "# print(y_pred[0],\"ddddd\",y_unseen[0])\n",
        "\n",
        "my_precision = precision_score(y_true, y_pred)\n",
        "my_recal = recall_score(y_true, y_pred)\n",
        "my_f1 = f1_score(y_true, y_pred)\n",
        "print(accuracy_score(y_true,y_pred))\n",
        "print(\"Precision:\", my_precision, \"Recall:\", my_recal, \"f1 score:\", my_f1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation on Unseen Dataset:\n",
            "(1502,)\n",
            "5/5 [==============================] - 0s 56ms/step - loss: 0.6829 - accuracy: 0.7267\n",
            "0.7266666666666667\n",
            "Precision: 0.7874015748031497 Recall: 0.8771929824561403 f1 score: 0.8298755186721992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2PgAsf8rU6k",
        "outputId": "8d32060d-5588-447f-c186-b349ea252d7d"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 1502)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bemjjqPHWbV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}